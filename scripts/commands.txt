
 python src/train.py day_time="2025-11-13_16-04-22" model_path="masani/SFT_gsm8k_Llama-2-7b-hf_epoch_1_global_step_29" experiment=grpo data=gsm8k data.train_dataset_type=adaptive data.sampler=null data.curriculum_config.zero_prob=0.1 trainer.n_gpus_per_node=8 actor_rollout_ref.actor.ppo_micro_batch_size_per_gpu=16 actor_rollout_ref.actor.ppo_mini_batch_size=256 actor_rollout_ref.rollout.log_prob_micro_batch_size_per_gpu=24 actor_rollout_ref.ref.log_prob_micro_batch_size_per_gpu=24 actor_rollout_ref.actor.optim.lr=1e-6 critic.optim.lr=1e-5 trainer.total_epochs=1000 actor_rollout_ref.actor.ppo_epochs=1 data.train_batch_size=256 trainer.test_freq=40 trainer.save_freq=2000


### END OF COMMAND ###


